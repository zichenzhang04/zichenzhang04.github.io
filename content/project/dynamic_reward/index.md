---
title: "<em>Simpler is Better:</em> Finding the Best Reward Function in Long Chain-of-Thought Reinforcement Learning for Small Language Models"

# subtitle: A Subtitle

summary: <div><p style=color:gray><a href="https://wln20.github.io/" target="_blank">Luning Wang</a>*, <b>Zichen Zhang</b>*, Junkuan Liu*.<br></p></div>We study three types of reward functions — normal, cosine, and dynamic — for long chain-of-thought reinforcement learning in Small Language Models, and find that the simple normal reward consistently outperforms more complex designs, suggesting that simpler rewards are good enough for eliciting reasoning in smaller models.

tags:
  - NLP
  - LLM
  - ML

date: "2025-04-27"

links:
  - icon_pack: fab
    name: <i class="fa-solid fa-image"></i> Poster
    url: uploads/dynamic_reward_poster.pdf
  - icon_pack: fab
    name: <i class="fa-brands fa-github"></i> Code
    url: "https://github.com/zichenzhang04/r1-dynamic-penalty"
  - icon_pack: fab
    name: <i class="fa-brands fa-slideshare"></i> Slides
    url: "https://docs.google.com/presentation/d/1j5nCwX4abzboFm4xz-lts9XMjLbNUPwESGXxPttx5Kg/edit?usp=sharing"

# Optional external URL for project (replaces project detail page).
external_link: https://github.com/zichenzhang04/r1-dynamic-penalty

image:
  caption: Proposed Pipeline
  focal_point: Smart
---
